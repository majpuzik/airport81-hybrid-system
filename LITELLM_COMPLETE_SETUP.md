# ğŸš€ LiteLLM Production Setup - KOMPLETNÃ

## âœ… ÃšspÄ›Å¡nÄ› nainstalovÃ¡no a nakonfigurovÃ¡no!

### ğŸ“Š AktuÃ¡lnÃ­ konfigurace:

| Komponenta | Hodnota |
|------------|---------|
| **API URL** | http://localhost:4000 |
| **Dashboard** | http://localhost:4000/ui |
| **API Key** | `sk-1234567890abcdef` |
| **UI Username** | `admin` |
| **UI Password** | `admin123` |
| **DatabÃ¡ze** | PostgreSQL (localhost:5432/litellm_db) |
| **Log** | `/tmp/litellm.log` |

### ğŸ¤– DostupnÃ© modely (Ollama):

- `llama3.1-70b` - Meta Llama 3.1 70B
- `llama3.3-70b` - Meta Llama 3.3 70B  
- `qwen2.5-coder-32b` - Qwen 2.5 Coder 32B
- `qwen2.5-32b` - Qwen 2.5 32B
- `mixtral-8x7b` - Mixtral MoE
- `mistral-7b` - Mistral 7B Instruct
- `deepseek-r1-14b` - DeepSeek R1 14B
- `czech-finance` - ÄŒeskÃ½ finanÄnÃ­ model

### ğŸš€ SpuÅ¡tÄ›nÃ­ serveru:

```bash
./start_litellm_production.sh
```

Nebo manuÃ¡lnÄ›:
```bash
cd ~
source litellm-venv/bin/activate
export LITELLM_MASTER_KEY="sk-1234567890abcdef"
export LITELLM_SALT_KEY="sk-SALT-KEY-DO-NOT-CHANGE-12345"
export DATABASE_URL="postgresql://litellm:litellm123@localhost:5432/litellm_db"
export UI_USERNAME="admin"
export UI_PASSWORD="admin123"
litellm --config litellm_production.yaml --port 4000
```

### ğŸ“ PÅ™Ã­klady pouÅ¾itÃ­:

#### 1. Seznam modelÅ¯:
```bash
curl http://localhost:4000/v1/models \
  -H "Authorization: Bearer sk-1234567890abcdef"
```

#### 2. Chat completion:
```bash
curl http://localhost:4000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer sk-1234567890abcdef" \
  -d '{
    "model": "llama3.1-70b",
    "messages": [
      {"role": "user", "content": "Ahoj, jak se mÃ¡Å¡?"}
    ],
    "temperature": 0.7
  }'
```

#### 3. Python klient:
```python
import openai

client = openai.OpenAI(
    base_url="http://localhost:4000/v1",
    api_key="sk-1234567890abcdef"
)

response = client.chat.completions.create(
    model="czech-finance",
    messages=[
        {"role": "user", "content": "Analyzuj tuto fakturu..."}
    ]
)
print(response.choices[0].message.content)
```

### ğŸŒ Dashboard:

1. OtevÅ™ete: http://localhost:4000/ui
2. PÅ™ihlaste se:
   - Username: `admin`
   - Password: `admin123`
3. V dashboardu mÅ¯Å¾ete:
   - Sledovat vyuÅ¾itÃ­ API
   - Spravovat API klÃ­Äe
   - Monitorovat vÃ½kon
   - Konfigurovat modely

### ğŸ’¾ DatabÃ¡ze:

PostgreSQL databÃ¡ze uklÃ¡dÃ¡:
- Konfiguraci modelÅ¯
- API klÃ­Äe a uÅ¾ivatele
- Logy poÅ¾adavkÅ¯
- Statistiky vyuÅ¾itÃ­

PÅ™ipojenÃ­ k databÃ¡zi:
```bash
psql -U litellm -d litellm_db -h localhost
# Heslo: litellm123
```

### ğŸ”§ ÃšdrÅ¾ba:

#### Restart serveru:
```bash
pkill -f litellm
./start_litellm_production.sh
```

#### PÅ™idÃ¡nÃ­ novÃ©ho modelu:
1. StÃ¡hnÄ›te model: `ollama pull nazev-modelu`
2. PÅ™idejte do `~/litellm_production.yaml`
3. Restartujte server

#### ZÃ¡loha databÃ¡ze:
```bash
pg_dump -U litellm -h localhost litellm_db > litellm_backup.sql
```

### ğŸ› ï¸ Å˜eÅ¡enÃ­ problÃ©mÅ¯:

| ProblÃ©m | Å˜eÅ¡enÃ­ |
|---------|--------|
| Port 4000 obsazenÃ½ | `lsof -ti :4000 \| xargs kill -9` |
| DatabÃ¡ze nefunguje | `brew services restart postgresql@16` |
| Ollama nebÄ›Å¾Ã­ | `ollama serve` |
| ChybÃ­ Prisma | `cd ~ && source litellm-venv/bin/activate && prisma generate` |

### ğŸ“ DÅ¯leÅ¾itÃ© soubory:

- Konfigurace: `~/litellm_production.yaml`
- PromÄ›nnÃ© prostÅ™edÃ­: `~/.env`
- Virtual environment: `~/litellm-venv/`
- Prisma schema: `~/schema.prisma`
- SpouÅ¡tÄ›cÃ­ skript: `~/start_litellm_production.sh`
- Log: `/tmp/litellm.log`

### ğŸ¯ VÃ½hody tohoto setupu:

1. **JednotnÃ© API** - vÅ¡echny modely pÅ™es OpenAI kompatibilnÃ­ rozhranÃ­
2. **Autentizace** - zabezpeÄenÃ½ pÅ™Ã­stup pomocÃ­ API klÃ­ÄÅ¯
3. **Perzistence** - konfigurace uloÅ¾enÃ¡ v databÃ¡zi
4. **Monitoring** - webovÃ½ dashboard pro sledovÃ¡nÃ­
5. **Å kÃ¡lovatelnost** - pÅ™ipraveno pro produkÄnÃ­ nasazenÃ­

---
**Instalace dokonÄena:** 20.8.2025
**Verze:** LiteLLM v1.75.8 + PostgreSQL 16.10