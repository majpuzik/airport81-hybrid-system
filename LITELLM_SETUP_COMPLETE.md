# ğŸš€ LiteLLM Proxy Server - INSTALACE DOKONÄŒENA

## âœ… STATUS: PLNÄš FUNKÄŒNÃ
- **Server bÄ›Å¾Ã­ na:** http://localhost:4000
- **PID procesu:** 15646
- **Master key:** `sk-1234567890abcdef`
- **Konfigurace:** `/Users/m.a.j.puzik/litellm_config.yaml`

## ğŸ“Š DOSTUPNÃ‰ MODELY (21 celkem)

### ğŸ–¥ï¸ LokÃ¡lnÃ­ Ollama modely (9):
âœ… **VelkÃ© modely (staÅ¾enÃ©):**
- `llama3.1-70b` - 42 GB âœ…
- `llama3.3-70b` - 42 GB âœ… 
- `qwen2.5-32b` - 19 GB âœ…
- `mixtral-8x7b` - Mixtral 8x7B

**StÅ™ednÃ­ a malÃ© modely:**
- `qwen2.5-coder-32b` - KÃ³dovacÃ­ model
- `mistral-7b` - Mistral 7B Instruct
- `qwen2.5-7b` - Qwen 2.5 7B
- `deepseek-r1-14b` - DeepSeek R1 14B
- `czech-finance` - ÄŒeskÃ½ finanÄnÃ­ model

### â˜ï¸ Cloud API modely:

**Claude (Anthropic) - 3 modely âœ… FUNKÄŒNÃ:**
- `claude-3-opus` - NejvÃ½konnÄ›jÅ¡Ã­
- `claude-3-sonnet` - VyvÃ¡Å¾enÃ½
- `claude-3-haiku` - RychlÃ½

**Gemini (Google) - 2 modely âœ… FUNKÄŒNÃ:**
- `gemini-pro` - Gemini 1.5 Pro
- `gemini-flash` - Gemini 1.5 Flash

**OpenAI - 7 modelÅ¯ âš ï¸ NEFUNKÄŒNÃ (pÅ™ekroÄena kvÃ³ta):**
- `gpt-4`, `gpt-4-turbo`, `gpt-4o`, `gpt-4o-mini`
- `gpt-3.5-turbo`, `o1-preview`, `o1-mini`

## ğŸ”§ POUÅ½ITÃ

### ZÃ¡kladnÃ­ pÅ™Ã­kaz:
```bash
curl http://localhost:4000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer sk-1234567890abcdef" \
  -d '{
    "model": "MODEL_NAME",
    "messages": [{"role": "user", "content": "Your message"}]
  }'
```

### Python pÅ™Ã­klad:
```python
from openai import OpenAI

client = OpenAI(
    api_key="sk-1234567890abcdef",
    base_url="http://localhost:4000/v1"
)

response = client.chat.completions.create(
    model="llama3.3-70b",  # nebo jinÃ½ model
    messages=[{"role": "user", "content": "Hello\!"}]
)
print(response.choices[0].message.content)
```

### DostupnÃ© endpointy:
- `GET /v1/models` - Seznam modelÅ¯
- `POST /v1/chat/completions` - Chat completions
- `POST /v1/completions` - Text completions
- `POST /v1/embeddings` - Embeddings

## ğŸ¯ DOPORUÄŒENÃ‰ MODELY

### Pro ÄeskÃ© texty:
1. `czech-finance` - SpecializovanÃ½ ÄeskÃ½ model
2. `claude-3-sonnet` - VÃ½bornÃ¡ ÄeÅ¡tina
3. `gemini-pro` - DobrÃ¡ ÄeÅ¡tina

### Pro programovÃ¡nÃ­:
1. `qwen2.5-coder-32b` - SpecializovanÃ½
2. `claude-3-opus` - NejlepÅ¡Ã­ kvalita
3. `deepseek-r1-14b` - RychlÃ½ a pÅ™esnÃ½

### Pro analÃ½zu dokumentÅ¯:
1. `llama3.3-70b` - VelkÃ¡ kontextovÃ¡ pamÄ›Å¥
2. `claude-3-opus` - DetailnÃ­ analÃ½za
3. `mixtral-8x7b` - RychlÃ© zpracovÃ¡nÃ­

## ğŸ“ SPRÃVA SERVERU

### Restart serveru:
```bash
# Zastavit
pkill -f litellm

# Spustit znovu
cd /Users/m.a.j.puzik
source litellm_env/bin/activate
litellm --config litellm_config.yaml --port 4000
```

### PÅ™idÃ¡nÃ­ novÃ©ho modelu:
1. StÃ¡hnout: `ollama pull model_name`
2. PÅ™idat do `/Users/m.a.j.puzik/litellm_config.yaml`
3. Restartovat server

### Logs:
```bash
# Sledovat logy
tail -f /tmp/litellm_final.log
```

## ğŸ”‘ API KLÃÄŒE

UloÅ¾enÃ© v `/Users/m.a.j.puzik/.env.litellm`:
- âœ… ANTHROPIC_API_KEY (Claude)
- âœ… GEMINI_API_KEY (Google)
- âš ï¸ OPENAI_API_KEY (kvÃ³ta pÅ™ekroÄena)

## ğŸ“Š STATISTIKY

- **FunkÄnÃ­ modely:** 14 (9 Ollama + 3 Claude + 2 Gemini)
- **CelkovÃ¡ velikost modelÅ¯:** ~103 GB
- **PodporovanÃ© jazyky:** 50+
- **Max kontext:** 128k tokenÅ¯ (nÄ›kterÃ© modely)

---
*Instalace dokonÄena: 2025-09-07 18:23*
*LiteLLM verze: nejnovÄ›jÅ¡Ã­*
